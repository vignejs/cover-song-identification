{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignejs/cover-song-identification/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL5hUmGqDQxA"
      },
      "source": [
        "# Siamese Convolutional Neural Network for Cover song identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l5r3R07OXeS",
        "outputId": "719e21cf-58d5-4c1f-a87c-7b718214ce07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_g8hOPzW4Ju",
        "outputId": "1aaabca9-796f-4767-f47f-fdb46cbd3cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pip install tensorflow-addons==0.9.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.9.1 in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.9.1) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkNC8_oi6bvp",
        "outputId": "f31e53d3-6f5f-41f0-bdeb-6f12dc374424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "import pickle\n",
        "import itertools as it\n",
        "import pandas as pd\n",
        "from scipy.linalg import block_diag\n",
        "from scipy import interpolate\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, AveragePooling2D, Layer, BatchNormalization, Lambda, ZeroPadding2D, ReLU, Average, Permute\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback, CSVLogger\n",
        "from tensorflow.python.framework.ops import Tensor\n",
        "from typing import Tuple, List\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBkVghK34gJ8"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-49-RYS8Yf2"
      },
      "source": [
        "feature_type = \"chroma_cens\"\n",
        "spect_len = 500\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    root = Path(\"/content/drive/My Drive/cosoid\")\n",
        "else:\n",
        "    root = Path.cwd()\n",
        "\n",
        "traindf = pd.HDFStore(root / 'datasets' / 'trainset.h5').select(feature_type)\n",
        "valdf = pd.HDFStore(root / 'datasets' / 'valset.h5').select(feature_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJV5FU4kZffN"
      },
      "source": [
        "traindf = traindf.groupby(by='work_id').filter(lambda x: len(x) == 13 * 12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TkPmCKLu5e"
      },
      "source": [
        "train = traindf.values.reshape(1000, 13, 12, 500)\n",
        "val = valdf.values.reshape(5000, 2, 12, 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkXHxtz3_51F"
      },
      "source": [
        "def gen_indexes(w_shape, p_shape):\n",
        "    \"\"\"generates combination of pair of indices for siamese input\n",
        "        w_shape: no of works\n",
        "        p_shape: no of performances\n",
        "    \"\"\"\n",
        "    indexes = list()\n",
        "    \n",
        "    p = list(it.permutations(range(p_shape), 2))\n",
        "    \n",
        "    r = range(w_shape)\n",
        "    for i in r:\n",
        "        np.random.seed(0)\n",
        "        rand = np.random.choice([x for x in r if x != i], size=len(p), replace=False)\n",
        "        for j, (x, y) in enumerate(p):\n",
        "            indexes.append([(i,x), (i,y)])\n",
        "            indexes.append([(i, x), (rand[j], y)])\n",
        "            \n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NRuy6ztFO_r"
      },
      "source": [
        "indexes_train = gen_indexes(1000, 13)\n",
        "indexes_val = gen_indexes(4000, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJnq6vm4xau"
      },
      "source": [
        "### Using keras.seqential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9sEzrGN4tLf"
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    '''Generates data for Keras'''\n",
        "    def __init__(self, data, indexes, batch_size=100, dim=(12, 1000), n_channels=1, shuffle=False, val=False):\n",
        "        '''Initialization'''\n",
        "        self.dim = dim\n",
        "        self.data = data\n",
        "        self.val = val\n",
        "        self.n_channels = n_channels\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = indexes    \n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        '''Denotes the number of batches per epoch'''\n",
        "        return int(np.floor(len(self.indexes) / self.batch_size)) \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Generate one batch of data'''\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # return data\n",
        "        return self.__data_generation(indexes)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        '''Updates indexes after each epoch'''\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)   \n",
        "    \n",
        "    def __data_augmentor(self, a):\n",
        "        \n",
        "        rng = int(np.random.normal() * spect_len)\n",
        "        aug = np.roll(a, rng, axis=1)\n",
        "\n",
        "        rng = int(np.random.normal() * 12)\n",
        "        aug = np.roll(aug, rng, axis=0)\n",
        "        \n",
        "        times = np.arange(0, spect_len)\n",
        "        func = interpolate.interp1d(times, aug, kind='nearest', fill_value='extrapolate')\n",
        "            \n",
        "        if np.random.uniform() < 0.3:\n",
        "            \n",
        "            rng = 1 + np.random.normal()  # random number to determine the factor of time stretching\n",
        "\n",
        "            if 0.7 <= rng <= 1.3:\n",
        "                times = np.linspace(0, spect_len - 1, int(spect_len * rng))\n",
        "                aug = func(times)  # applying time stretching\n",
        "                \n",
        "        if np.random.uniform() < 0.3:\n",
        "            rng = np.random.uniform()  # random number to determine which operation to apply for time warping\n",
        "\n",
        "            if rng < 0.3:  # silence\n",
        "                # each frame has a probability of 0.1 to be silenced\n",
        "                silence_idxs = np.random.choice([False, True], size=times.size, p=[.9, .1])\n",
        "                aug[:, silence_idxs] = np.zeros((12, 1))\n",
        "\n",
        "            elif rng < 0.7:  # duplicate\n",
        "                # each frame has a probability of 0.15 to be duplicated\n",
        "                duplicate_idxs = np.random.choice([False, True], size=times.size, p=[.85, .15])\n",
        "                times = np.sort(np.concatenate((times, times[duplicate_idxs])))\n",
        "                aug = func(times)\n",
        "\n",
        "            else:  # remove\n",
        "                # each frame has a probability of 0.1 to be removed\n",
        "                remaining_idxs = np.random.choice([False, True], size=times.size, p=[.1, .9])\n",
        "                times = times[remaining_idxs]\n",
        "                aug = func(times)\n",
        "\n",
        "        \n",
        "        if aug.shape[1] > spect_len:\n",
        "            aug = aug[:, :spect_len]\n",
        "        else:\n",
        "            aug = np.pad(aug, ((0, 0), (0, spect_len - aug.shape[1])), 'wrap')   \n",
        "\n",
        "        return aug\n",
        "    \n",
        "    def _data_augmentor(self, a):\n",
        "        if self.val:\n",
        "            return a\n",
        "        else:\n",
        "            return self.__data_augmentor(a)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        '''Generates data containing batch_size samples''' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X1 = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n",
        "        X2 = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n",
        "        Y = np.empty((self.batch_size, 1), dtype=np.int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, (x, y) in enumerate(indexes):\n",
        "            # sample sample\n",
        "            r1 = self.data[x]\n",
        "            r2 = self.data[y]\n",
        "\n",
        "            # augment sample\n",
        "            r1 = self._data_augmentor(r1)\n",
        "            r2 = self._data_augmentor(r2)\n",
        "\n",
        "            # store sample\n",
        "            X1[i, ] = r1.reshape(12, spect_len, 1)\n",
        "            X2[i, ] = r2.reshape(12, spect_len, 1)\n",
        "\n",
        "            # Store class\n",
        "            if x[0] == y[0]:\n",
        "                Y[i, ] = [0]\n",
        "            else:\n",
        "                Y[i, ] = [1]     \n",
        "\n",
        "        return [X1, X2], np.array(Y, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoHHfyFAKHCW"
      },
      "source": [
        "# Parameters\n",
        "params = {'dim': (12, spect_len),\n",
        "          'batch_size': 128,\n",
        "          'n_channels': 1,\n",
        "          'shuffle': True}\n",
        "\n",
        "training_generator = DataGenerator(train, indexes_train, **params)\n",
        "validation_generator = DataGenerator(val, indexes_val, **params, val=True)\n",
        "\n",
        "def tr_generator():\n",
        "    multi_enqueuer = tf.keras.utils.OrderedEnqueuer(training_generator, use_multiprocessing=True, shuffle=False)\n",
        "    multi_enqueuer.start(workers=4, max_queue_size=5)\n",
        "    while True:\n",
        "        yield next(multi_enqueuer.get())\n",
        "\n",
        "def va_generator():\n",
        "    multi_enqueuer = tf.keras.utils.OrderedEnqueuer(validation_generator, use_multiprocessing=True, shuffle=False)\n",
        "    multi_enqueuer.start(workers=4, max_queue_size=5)\n",
        "    while True:\n",
        "        yield next(multi_enqueuer.get())\n",
        "\n",
        "\n",
        "training_dataset = tr_generator()\n",
        "validation_dataset = va_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDxId9xJP4EL"
      },
      "source": [
        "### ADAMScheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otrg-aalOVAZ"
      },
      "source": [
        "class ADAMScheduler(Callback):\n",
        "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
        "    # Usage\n",
        "        ```python\n",
        "            schedule = ADAMScheduler(min_lr=1e-5,\n",
        "                                     max_lr=1e-2,\n",
        "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
        "                                     lr_decay=0.9,\n",
        "                                     cycle_length=5,\n",
        "                                     mult_factor=1.5)\n",
        "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
        "        ```\n",
        "    # Arguments\n",
        "        min_lr: The lower bound of the learning rate range for the experiment.\n",
        "        max_lr: The upper bound of the learning rate range for the experiment.\n",
        "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
        "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
        "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
        "        cycle_length: Initial number of epochs in a cycle.\n",
        "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
        "    # References\n",
        "        Blog post: jeremyjordan.me/nn-learning-rate\n",
        "        Original paper: http://arxiv.org/abs/1608.03983\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 min_lr,\n",
        "                 max_lr,\n",
        "                 steps_per_epoch,\n",
        "                 lr_decay=1,\n",
        "                 cycle_length=10,\n",
        "                 mult_factor=2):\n",
        "\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.lr_decay = lr_decay\n",
        "\n",
        "        self.batch_since_restart = 0\n",
        "        self.next_restart = cycle_length\n",
        "\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "        self.cycle_length = cycle_length\n",
        "        self.mult_factor = mult_factor\n",
        "\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        '''Calculate the learning rate.'''\n",
        "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
        "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
        "        logs = logs or {}\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.max_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        '''Record previous batch statistics and update the learning rate.'''\n",
        "        logs = logs or {}\n",
        "        self.history.setdefault('learning_rate', []).append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "        self.batch_since_restart += 1\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.clr())\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.ep_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
        "        print(f\"Current learning rate {K.get_value(self.model.optimizer.learning_rate)}\")\n",
        "        print(f\"Elapsed time : {time.time() - self.ep_start:.2f}s\")\n",
        "        if epoch + 1 == self.next_restart:\n",
        "            print('Restarts')\n",
        "            self.batch_since_restart = 0\n",
        "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
        "            self.next_restart += self.cycle_length\n",
        "            self.max_lr *= self.lr_decay\n",
        "            self.best_weights = self.model.get_weights()\n",
        "            self.model.save(root / \"weights/weights.best-{:.2e}-epoch-{:05d}.hdf5\".format(self.model.count_params(), epoch + 1))\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
        "        self.model.set_weights(self.best_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duECInUZt758"
      },
      "source": [
        "### Siamese Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe2BSM1cC1he"
      },
      "source": [
        "def squared_differences(pair_of_tensors):\n",
        "    x, y = pair_of_tensors\n",
        "    return K.square(x - y)\n",
        "\n",
        "def l2_norm(x, axis=None):\n",
        "    \"\"\"\n",
        "    takes an input tensor and returns the l2 norm along specified axis\n",
        "    \"\"\"\n",
        "\n",
        "    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)\n",
        "    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))\n",
        "\n",
        "    return norm\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1) \n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
        "\n",
        "def W_init(shape, dtype=None):\n",
        "    \"\"\"Initialize weights\"\"\"\n",
        "    values = np.random.normal(loc=0, scale=1e-2, size=shape)\n",
        "    return K.variable(values, dtype=dtype)\n",
        "\n",
        "def W_init_dense(shape, dtype=None):\n",
        "    \"\"\"Initialize weights\"\"\"\n",
        "    values = np.random.normal(loc=0, scale=2e-1, size=shape)\n",
        "    return K.variable(values, dtype=dtype)\n",
        " \n",
        "def b_init(shape, dtype=None):\n",
        "    \"\"\"Initialize bias\"\"\"\n",
        "    values = np.random.normal(loc=0.5, scale=1e-2, size=shape)\n",
        "    return K.variable(values, dtype=dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52JINqUwDpar",
        "outputId": "570a214e-d807-4864-8f5e-dd8a91fbc264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_base_network(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D(padding=(3, 0), input_shape=input_shape))\n",
        "    model.add(Conv2D(32, (7, 7), strides=(1, 3), kernel_initializer=W_init, bias_initializer=b_init))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(ZeroPadding2D(padding=(2, 0)))\n",
        "    model.add(Conv2D(32, (5, 5), strides=(1, 2), kernel_initializer=W_init, bias_initializer=b_init))\n",
        "    model.add(ReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(ZeroPadding2D(padding=(2, 0)))\n",
        "    model.add(Conv2D(32, (5, 5), strides=(1, 2), kernel_initializer=W_init, bias_initializer=b_init))\n",
        "    model.add(ReLU())\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(ZeroPadding2D(padding=(2, 0)))\n",
        "    model.add(Conv2D(32, (5, 5), strides=(2, 2), kernel_initializer=W_init, bias_initializer=b_init))\n",
        "    model.add(ReLU())\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='sigmoid', kernel_initializer=W_init_dense, bias_initializer=b_init))\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_twin():\n",
        "    input_shape = (12, spect_len, 1)\n",
        "    original_input = Input(shape=input_shape, name=\"input_1\")\n",
        "    cover_input = Input(shape=input_shape, name=\"input_2\")\n",
        "    model = create_base_network(input_shape)\n",
        "    original_model = model(original_input)\n",
        "    cover_model = model(cover_input)\n",
        "\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([original_model, cover_model])\n",
        "\n",
        "    output = Dense(1, activation='sigmoid')(L1_distance)\n",
        "\n",
        "    model = Model(inputs=[original_input, cover_input], outputs=[output])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_twin()\n",
        "best_weights_file = \"{}/weights/weights.best-{:.2e}.hdf5\".format(root, model.count_params())\n",
        "\n",
        "opt = tfa.optimizers.AdamW(weight_decay=1e-4, learning_rate=1e-2)\n",
        "\n",
        "custom_objects = {\"contrastive_loss\": contrastive_loss,\n",
        "                  \"acc\": acc,\n",
        "                  \"W_init\": W_init,\n",
        "                  \"W_init_dense\": W_init_dense,\n",
        "                  \"b_init\": b_init}\n",
        "\n",
        "# model = load_model(best_weights_file, custom_objects=custom_objects)\n",
        "model.compile(loss=contrastive_loss, optimizer=opt, metrics=[acc])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d (ZeroPadding2 (None, 18, 500, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 12, 165, 32)       1600      \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 12, 165, 32)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 12, 165, 32)       128       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 16, 165, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 12, 81, 32)        25632     \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 12, 81, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12, 40, 32)        128       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 16, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 18, 32)        25632     \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 12, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 18, 32)        128       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 16, 18, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 7, 32)          25632     \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 6, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 32)          128       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               66048     \n",
            "=================================================================\n",
            "Total params: 145,056\n",
            "Trainable params: 144,800\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 500, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 12, 500, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 512)          145056      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 512)          0           sequential[0][0]                 \n",
            "                                                                 sequential[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            513         lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 145,569\n",
            "Trainable params: 145,313\n",
            "Non-trainable params: 256\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEIEPmuYuDEy"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNnyMuVRKJDO"
      },
      "source": [
        "checkpoint = ModelCheckpoint(best_weights_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "csv_logger = CSVLogger(f\"{root}/logs/training-{model.count_params():.2e}.csv\", append=False)\n",
        "\n",
        "lr_schedule = ADAMScheduler(min_lr=0,\n",
        "                            max_lr=1e-2,\n",
        "                            steps_per_epoch=len(training_generator),\n",
        "                            lr_decay=0.9,\n",
        "                            cycle_length=50,\n",
        "                            mult_factor=1)\n",
        "\n",
        "callbacks = [checkpoint, lr_schedule, csv_logger]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvk3bfpCq8ya",
        "scrolled": true,
        "outputId": "d5a624c3-8651-4554-b622-1bbe2dc729c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train model on dataset (sequence)\n",
        "history = model.fit(training_dataset,\n",
        "                    validation_data=validation_dataset,\n",
        "                    steps_per_epoch=len(training_generator),\n",
        "                    validation_steps=len(validation_generator),\n",
        "                    use_multiprocessing=False,\n",
        "                    workers=1,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks,\n",
        "                    epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.6737\n",
            "Epoch 00001: val_loss improved from inf to 0.58812, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.009990133345127106\n",
            "Elapsed time : 97.11s\n",
            "2437/2437 [==============================] - 94s 38ms/step - loss: 0.5980 - accuracy: 0.6737 - val_loss: 0.5881 - val_accuracy: 0.6936\n",
            "Epoch 2/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.5142 - accuracy: 0.7443\n",
            "Epoch 00002: val_loss did not improve from 0.58812\n",
            "Current learning rate 0.00996057316660881\n",
            "Elapsed time : 92.74s\n",
            "2437/2437 [==============================] - 93s 38ms/step - loss: 0.5142 - accuracy: 0.7443 - val_loss: 0.5973 - val_accuracy: 0.6896\n",
            "Epoch 3/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.7676\n",
            "Epoch 00003: val_loss improved from 0.58812 to 0.44761, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.009911436587572098\n",
            "Elapsed time : 94.75s\n",
            "2437/2437 [==============================] - 95s 39ms/step - loss: 0.4820 - accuracy: 0.7676 - val_loss: 0.4476 - val_accuracy: 0.7906\n",
            "Epoch 4/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.7779\n",
            "Epoch 00004: val_loss improved from 0.44761 to 0.43570, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.009842915460467339\n",
            "Elapsed time : 97.06s\n",
            "2437/2437 [==============================] - 97s 40ms/step - loss: 0.4660 - accuracy: 0.7779 - val_loss: 0.4357 - val_accuracy: 0.8012\n",
            "Epoch 5/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.4541 - accuracy: 0.7853\n",
            "Epoch 00005: val_loss did not improve from 0.43570\n",
            "Current learning rate 0.009755282662808895\n",
            "Elapsed time : 95.14s\n",
            "2437/2437 [==============================] - 95s 39ms/step - loss: 0.4540 - accuracy: 0.7853 - val_loss: 0.6174 - val_accuracy: 0.7200\n",
            "Epoch 6/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7912\n",
            "Epoch 00006: val_loss improved from 0.43570 to 0.42253, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.009648882783949375\n",
            "Elapsed time : 97.05s\n",
            "2437/2437 [==============================] - 97s 40ms/step - loss: 0.4443 - accuracy: 0.7912 - val_loss: 0.4225 - val_accuracy: 0.8059\n",
            "Epoch 7/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7954\n",
            "Epoch 00007: val_loss did not improve from 0.42253\n",
            "Current learning rate 0.009524134919047356\n",
            "Elapsed time : 97.45s\n",
            "2437/2437 [==============================] - 97s 40ms/step - loss: 0.4376 - accuracy: 0.7954 - val_loss: 0.4256 - val_accuracy: 0.8033\n",
            "Epoch 8/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.7986\n",
            "Epoch 00008: val_loss improved from 0.42253 to 0.39331, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.009381533600389957\n",
            "Elapsed time : 97.73s\n",
            "2437/2437 [==============================] - 98s 40ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.3933 - val_accuracy: 0.8298\n",
            "Epoch 9/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.8004\n",
            "Epoch 00009: val_loss did not improve from 0.39331\n",
            "Current learning rate 0.009221639484167099\n",
            "Elapsed time : 98.72s\n",
            "2437/2437 [==============================] - 99s 40ms/step - loss: 0.4277 - accuracy: 0.8004 - val_loss: 0.3967 - val_accuracy: 0.8207\n",
            "Epoch 10/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.8024\n",
            "Epoch 00010: val_loss improved from 0.39331 to 0.37914, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.009045084938406944\n",
            "Elapsed time : 98.97s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.4259 - accuracy: 0.8024 - val_loss: 0.3791 - val_accuracy: 0.8343\n",
            "Epoch 11/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8048\n",
            "Epoch 00011: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.008852566592395306\n",
            "Elapsed time : 97.86s\n",
            "2437/2437 [==============================] - 98s 40ms/step - loss: 0.4213 - accuracy: 0.8048 - val_loss: 0.4382 - val_accuracy: 0.7962\n",
            "Epoch 12/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.8053\n",
            "Epoch 00012: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.008644843474030495\n",
            "Elapsed time : 98.57s\n",
            "2437/2437 [==============================] - 99s 40ms/step - loss: 0.4196 - accuracy: 0.8053 - val_loss: 0.5566 - val_accuracy: 0.7214\n",
            "Epoch 13/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8065\n",
            "Epoch 00013: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.008422735147178173\n",
            "Elapsed time : 98.15s\n",
            "2437/2437 [==============================] - 98s 40ms/step - loss: 0.4173 - accuracy: 0.8065 - val_loss: 0.4108 - val_accuracy: 0.8104\n",
            "Epoch 14/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8077\n",
            "Epoch 00014: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.008187119849026203\n",
            "Elapsed time : 99.49s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.4158 - accuracy: 0.8077 - val_loss: 0.4064 - val_accuracy: 0.8172\n",
            "Epoch 15/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.8090\n",
            "Epoch 00015: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.007938926108181477\n",
            "Elapsed time : 99.40s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.4137 - accuracy: 0.8090 - val_loss: 0.4537 - val_accuracy: 0.7872\n",
            "Epoch 16/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.8096\n",
            "Epoch 00016: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.007679134141653776\n",
            "Elapsed time : 100.77s\n",
            "2437/2437 [==============================] - 101s 41ms/step - loss: 0.4107 - accuracy: 0.8096 - val_loss: 0.3810 - val_accuracy: 0.8409\n",
            "Epoch 17/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8122\n",
            "Epoch 00017: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.007408768404275179\n",
            "Elapsed time : 99.69s\n",
            "2437/2437 [==============================] - 100s 41ms/step - loss: 0.4088 - accuracy: 0.8122 - val_loss: 0.4574 - val_accuracy: 0.7828\n",
            "Epoch 18/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8121\n",
            "Epoch 00018: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0071288966573774815\n",
            "Elapsed time : 99.15s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.4077 - accuracy: 0.8121 - val_loss: 0.5143 - val_accuracy: 0.7663\n",
            "Epoch 19/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.8131\n",
            "Epoch 00019: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0068406229838728905\n",
            "Elapsed time : 99.67s\n",
            "2437/2437 [==============================] - 100s 41ms/step - loss: 0.4063 - accuracy: 0.8131 - val_loss: 0.3977 - val_accuracy: 0.8193\n",
            "Epoch 20/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.8139\n",
            "Epoch 00020: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.006545084994286299\n",
            "Elapsed time : 99.60s\n",
            "2437/2437 [==============================] - 100s 41ms/step - loss: 0.4058 - accuracy: 0.8139 - val_loss: 0.4043 - val_accuracy: 0.8158\n",
            "Epoch 21/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4045 - accuracy: 0.8135\n",
            "Epoch 00021: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0062434496358036995\n",
            "Elapsed time : 99.97s\n",
            "2437/2437 [==============================] - 100s 41ms/step - loss: 0.4045 - accuracy: 0.8135 - val_loss: 0.3840 - val_accuracy: 0.8254\n",
            "Epoch 22/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.8148\n",
            "Epoch 00022: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.005936906673014164\n",
            "Elapsed time : 99.14s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.4027 - accuracy: 0.8148 - val_loss: 0.4574 - val_accuracy: 0.7823\n",
            "Epoch 23/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.4016 - accuracy: 0.8157\n",
            "Epoch 00023: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.005626666359603405\n",
            "Elapsed time : 98.33s\n",
            "2437/2437 [==============================] - 98s 40ms/step - loss: 0.4015 - accuracy: 0.8158 - val_loss: 0.5132 - val_accuracy: 0.7536\n",
            "Epoch 24/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.8176\n",
            "Epoch 00024: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.005313952453434467\n",
            "Elapsed time : 98.87s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.3979 - accuracy: 0.8176 - val_loss: 0.4568 - val_accuracy: 0.7888\n",
            "Epoch 25/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.8170\n",
            "Epoch 00025: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.004999999888241291\n",
            "Elapsed time : 99.64s\n",
            "2437/2437 [==============================] - 100s 41ms/step - loss: 0.3979 - accuracy: 0.8170 - val_loss: 0.5123 - val_accuracy: 0.7533\n",
            "Epoch 26/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8180\n",
            "Epoch 00026: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.004686047323048115\n",
            "Elapsed time : 98.57s\n",
            "2437/2437 [==============================] - 99s 40ms/step - loss: 0.3970 - accuracy: 0.8180 - val_loss: 0.3836 - val_accuracy: 0.8282\n",
            "Epoch 27/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8180\n",
            "Epoch 00027: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.004373333882540464\n",
            "Elapsed time : 98.19s\n",
            "2437/2437 [==============================] - 98s 40ms/step - loss: 0.3972 - accuracy: 0.8180 - val_loss: 0.3971 - val_accuracy: 0.8209\n",
            "Epoch 28/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.3940 - accuracy: 0.8201\n",
            "Epoch 00028: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.004063093569129705\n",
            "Elapsed time : 98.73s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.3940 - accuracy: 0.8201 - val_loss: 0.3883 - val_accuracy: 0.8272\n",
            "Epoch 29/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8197\n",
            "Epoch 00029: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.00375655060634017\n",
            "Elapsed time : 99.11s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.3937 - accuracy: 0.8197 - val_loss: 0.4585 - val_accuracy: 0.7881\n",
            "Epoch 30/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8216\n",
            "Epoch 00030: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.003454915015026927\n",
            "Elapsed time : 98.63s\n",
            "2437/2437 [==============================] - 99s 40ms/step - loss: 0.3915 - accuracy: 0.8216 - val_loss: 0.3889 - val_accuracy: 0.8311\n",
            "Epoch 31/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8213\n",
            "Epoch 00031: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.003159377258270979\n",
            "Elapsed time : 99.11s\n",
            "2437/2437 [==============================] - 99s 41ms/step - loss: 0.3923 - accuracy: 0.8213 - val_loss: 0.3939 - val_accuracy: 0.8221\n",
            "Epoch 32/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8203\n",
            "Epoch 00032: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.002871103584766388\n",
            "Elapsed time : 98.28s\n",
            "2437/2437 [==============================] - 98s 40ms/step - loss: 0.3918 - accuracy: 0.8203 - val_loss: 0.3967 - val_accuracy: 0.8219\n",
            "Epoch 33/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8233\n",
            "Epoch 00033: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.002591231605038047\n",
            "Elapsed time : 102.01s\n",
            "2437/2437 [==============================] - 102s 42ms/step - loss: 0.3893 - accuracy: 0.8233 - val_loss: 0.4256 - val_accuracy: 0.8035\n",
            "Epoch 34/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8229\n",
            "Epoch 00034: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0023208661004900932\n",
            "Elapsed time : 101.69s\n",
            "2437/2437 [==============================] - 102s 42ms/step - loss: 0.3890 - accuracy: 0.8229 - val_loss: 0.3980 - val_accuracy: 0.8241\n",
            "Epoch 35/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8231\n",
            "Epoch 00035: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0020610736683011055\n",
            "Elapsed time : 101.07s\n",
            "2437/2437 [==============================] - 101s 41ms/step - loss: 0.3885 - accuracy: 0.8231 - val_loss: 0.4048 - val_accuracy: 0.8163\n",
            "Epoch 36/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8241\n",
            "Epoch 00036: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0018128800438717008\n",
            "Elapsed time : 101.22s\n",
            "2437/2437 [==============================] - 101s 42ms/step - loss: 0.3873 - accuracy: 0.8241 - val_loss: 0.4045 - val_accuracy: 0.8215\n",
            "Epoch 37/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8239\n",
            "Epoch 00037: val_loss did not improve from 0.37914\n",
            "Current learning rate 0.0015772645128890872\n",
            "Elapsed time : 101.79s\n",
            "2437/2437 [==============================] - 102s 42ms/step - loss: 0.3873 - accuracy: 0.8239 - val_loss: 0.4220 - val_accuracy: 0.8059\n",
            "Epoch 38/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8246\n",
            "Epoch 00038: val_loss improved from 0.37914 to 0.37037, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.0013551568845286965\n",
            "Elapsed time : 103.36s\n",
            "2437/2437 [==============================] - 103s 42ms/step - loss: 0.3859 - accuracy: 0.8246 - val_loss: 0.3704 - val_accuracy: 0.8393\n",
            "Epoch 39/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8251\n",
            "Epoch 00039: val_loss did not improve from 0.37037\n",
            "Current learning rate 0.0011474337661638856\n",
            "Elapsed time : 102.66s\n",
            "2437/2437 [==============================] - 103s 42ms/step - loss: 0.3860 - accuracy: 0.8251 - val_loss: 0.3956 - val_accuracy: 0.8263\n",
            "Epoch 40/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8254\n",
            "Epoch 00040: val_loss did not improve from 0.37037\n",
            "Current learning rate 0.0009549150126986206\n",
            "Elapsed time : 102.48s\n",
            "2437/2437 [==============================] - 102s 42ms/step - loss: 0.3848 - accuracy: 0.8254 - val_loss: 0.4138 - val_accuracy: 0.8125\n",
            "Epoch 41/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8257\n",
            "Epoch 00041: val_loss did not improve from 0.37037\n",
            "Current learning rate 0.000778360350523144\n",
            "Elapsed time : 103.07s\n",
            "2437/2437 [==============================] - 103s 42ms/step - loss: 0.3849 - accuracy: 0.8257 - val_loss: 0.3815 - val_accuracy: 0.8358\n",
            "Epoch 42/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8263\n",
            "Epoch 00042: val_loss did not improve from 0.37037\n",
            "Current learning rate 0.0006184665835462511\n",
            "Elapsed time : 103.23s\n",
            "2437/2437 [==============================] - 103s 42ms/step - loss: 0.3837 - accuracy: 0.8263 - val_loss: 0.3830 - val_accuracy: 0.8324\n",
            "Epoch 43/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8272\n",
            "Epoch 00043: val_loss did not improve from 0.37037\n",
            "Current learning rate 0.0004758647410199046\n",
            "Elapsed time : 103.67s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.3835 - accuracy: 0.8272 - val_loss: 0.3962 - val_accuracy: 0.8254\n",
            "Epoch 44/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8265\n",
            "Epoch 00044: val_loss improved from 0.37037 to 0.36510, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.0003511175746098161\n",
            "Elapsed time : 105.27s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.3849 - accuracy: 0.8265 - val_loss: 0.3651 - val_accuracy: 0.8488\n",
            "Epoch 45/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8266\n",
            "Epoch 00045: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.00024471740471199155\n",
            "Elapsed time : 104.43s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.3856 - accuracy: 0.8266 - val_loss: 0.3884 - val_accuracy: 0.8304\n",
            "Epoch 46/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.8270\n",
            "Epoch 00046: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.0001570841995999217\n",
            "Elapsed time : 103.85s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.3886 - accuracy: 0.8270 - val_loss: 0.3899 - val_accuracy: 0.8354\n",
            "Epoch 47/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8252\n",
            "Epoch 00047: val_loss did not improve from 0.36510\n",
            "Current learning rate 8.85637491592206e-05\n",
            "Elapsed time : 103.83s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.3965 - accuracy: 0.8252 - val_loss: 0.3980 - val_accuracy: 0.8368\n",
            "Epoch 48/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8193\n",
            "Epoch 00048: val_loss did not improve from 0.36510\n",
            "Current learning rate 3.942649345844984e-05\n",
            "Elapsed time : 103.87s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.4166 - accuracy: 0.8193 - val_loss: 0.4302 - val_accuracy: 0.8229\n",
            "Epoch 49/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.8039\n",
            "Epoch 00049: val_loss did not improve from 0.36510\n",
            "Current learning rate 9.866357686405536e-06\n",
            "Elapsed time : 104.48s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.4598 - accuracy: 0.8039 - val_loss: 0.4866 - val_accuracy: 0.8051\n",
            "Epoch 50/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.7622\n",
            "Epoch 00050: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.0\n",
            "Elapsed time : 105.32s\n",
            "Restarts\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.5459 - accuracy: 0.7622 - val_loss: 0.6145 - val_accuracy: 0.6728\n",
            "Epoch 51/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.6634\n",
            "Epoch 00051: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008991120383143425\n",
            "Elapsed time : 105.41s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.6053 - accuracy: 0.6634 - val_loss: 0.7933 - val_accuracy: 0.5569\n",
            "Epoch 52/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.7428\n",
            "Epoch 00052: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.00896451622247696\n",
            "Elapsed time : 105.02s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.5172 - accuracy: 0.7428 - val_loss: 0.4782 - val_accuracy: 0.7739\n",
            "Epoch 53/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4874 - accuracy: 0.7644\n",
            "Epoch 00053: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008920292370021343\n",
            "Elapsed time : 104.52s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.4873 - accuracy: 0.7644 - val_loss: 0.6287 - val_accuracy: 0.6691\n",
            "Epoch 54/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.7756\n",
            "Epoch 00054: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008858623914420605\n",
            "Elapsed time : 104.69s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4709 - accuracy: 0.7756 - val_loss: 0.4526 - val_accuracy: 0.7832\n",
            "Epoch 55/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4583 - accuracy: 0.7828\n",
            "Epoch 00055: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008779753930866718\n",
            "Elapsed time : 106.15s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.4583 - accuracy: 0.7829 - val_loss: 0.5187 - val_accuracy: 0.7511\n",
            "Epoch 56/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4498 - accuracy: 0.7882\n",
            "Epoch 00056: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.00868399441242218\n",
            "Elapsed time : 106.18s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.4193 - val_accuracy: 0.8066\n",
            "Epoch 57/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4434 - accuracy: 0.7912\n",
            "Epoch 00057: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008571721613407135\n",
            "Elapsed time : 105.24s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4434 - accuracy: 0.7912 - val_loss: 0.4708 - val_accuracy: 0.7777\n",
            "Epoch 58/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7941\n",
            "Epoch 00058: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008443379774689674\n",
            "Elapsed time : 106.07s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.4386 - accuracy: 0.7941 - val_loss: 0.4998 - val_accuracy: 0.7631\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.008299475535750389\n",
            "Elapsed time : 104.87s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4327 - accuracy: 0.7971 - val_loss: 0.3903 - val_accuracy: 0.8264\n",
            "Epoch 60/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4309 - accuracy: 0.7984\n",
            "Epoch 00060: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.00814057607203722\n",
            "Elapsed time : 104.69s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4309 - accuracy: 0.7984 - val_loss: 0.4209 - val_accuracy: 0.8061\n",
            "Epoch 61/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8013\n",
            "Epoch 00061: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.007967310026288033\n",
            "Elapsed time : 105.17s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4272 - accuracy: 0.8013 - val_loss: 0.4505 - val_accuracy: 0.7877\n",
            "Epoch 62/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8024\n",
            "Epoch 00062: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.007780358660966158\n",
            "Elapsed time : 105.24s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4243 - accuracy: 0.8024 - val_loss: 0.4400 - val_accuracy: 0.7959\n",
            "Epoch 63/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8043\n",
            "Epoch 00063: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.007580461911857128\n",
            "Elapsed time : 105.64s\n",
            "2437/2437 [==============================] - 106s 43ms/step - loss: 0.4208 - accuracy: 0.8043 - val_loss: 0.4079 - val_accuracy: 0.8181\n",
            "Epoch 64/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8049\n",
            "Epoch 00064: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.007368408143520355\n",
            "Elapsed time : 105.19s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4197 - accuracy: 0.8049 - val_loss: 0.4006 - val_accuracy: 0.8209\n",
            "Epoch 65/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.8057\n",
            "Epoch 00065: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.007145033683627844\n",
            "Elapsed time : 105.11s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4183 - accuracy: 0.8057 - val_loss: 0.4729 - val_accuracy: 0.7722\n",
            "Epoch 66/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.8071\n",
            "Epoch 00066: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.006911220494657755\n",
            "Elapsed time : 105.11s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4160 - accuracy: 0.8071 - val_loss: 0.4414 - val_accuracy: 0.7894\n",
            "Epoch 67/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.8075\n",
            "Epoch 00067: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.006667891517281532\n",
            "Elapsed time : 105.18s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4147 - accuracy: 0.8075 - val_loss: 0.3677 - val_accuracy: 0.8374\n",
            "Epoch 68/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.8091\n",
            "Epoch 00068: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.006416006945073605\n",
            "Elapsed time : 105.90s\n",
            "2437/2437 [==============================] - 106s 43ms/step - loss: 0.4136 - accuracy: 0.8091 - val_loss: 0.3906 - val_accuracy: 0.8282\n",
            "Epoch 69/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8093\n",
            "Epoch 00069: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.0061565604992210865\n",
            "Elapsed time : 105.01s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4113 - accuracy: 0.8093 - val_loss: 0.4342 - val_accuracy: 0.7946\n",
            "Epoch 70/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.8089\n",
            "Epoch 00070: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.005890576634556055\n",
            "Elapsed time : 105.48s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4122 - accuracy: 0.8089 - val_loss: 0.3659 - val_accuracy: 0.8432\n",
            "Epoch 71/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.8123\n",
            "Epoch 00071: val_loss did not improve from 0.36510\n",
            "Current learning rate 0.005619104485958815\n",
            "Elapsed time : 105.13s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4078 - accuracy: 0.8123 - val_loss: 0.4019 - val_accuracy: 0.8144\n",
            "Epoch 72/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.8126\n",
            "Epoch 00072: val_loss improved from 0.36510 to 0.36152, saving model to /content/drive/My Drive/cosoid/weights/weights.best-1.46e+05.hdf5\n",
            "Current learning rate 0.005343216005712748\n",
            "Elapsed time : 106.74s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.4067 - accuracy: 0.8126 - val_loss: 0.3615 - val_accuracy: 0.8451\n",
            "Epoch 73/100\n",
            "2435/2437 [============================>.] - ETA: 0s - loss: 0.4056 - accuracy: 0.8130\n",
            "Epoch 00073: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.005063999444246292\n",
            "Elapsed time : 105.50s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4056 - accuracy: 0.8130 - val_loss: 0.3695 - val_accuracy: 0.8382\n",
            "Epoch 74/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4066 - accuracy: 0.8130\n",
            "Epoch 00074: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.004782557487487793\n",
            "Elapsed time : 105.05s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4066 - accuracy: 0.8130 - val_loss: 0.4245 - val_accuracy: 0.8102\n",
            "Epoch 75/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.8130\n",
            "Epoch 00075: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0044999998062849045\n",
            "Elapsed time : 105.51s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4056 - accuracy: 0.8130 - val_loss: 0.4243 - val_accuracy: 0.8024\n",
            "Epoch 76/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.8145\n",
            "Epoch 00076: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.004217442590743303\n",
            "Elapsed time : 105.23s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4030 - accuracy: 0.8145 - val_loss: 0.4304 - val_accuracy: 0.8048\n",
            "Epoch 77/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.4033 - accuracy: 0.8143\n",
            "Epoch 00077: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.003936000633984804\n",
            "Elapsed time : 105.16s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4033 - accuracy: 0.8143 - val_loss: 0.4108 - val_accuracy: 0.8094\n",
            "Epoch 78/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.8147\n",
            "Epoch 00078: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0036567840725183487\n",
            "Elapsed time : 105.50s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.4032 - accuracy: 0.8147 - val_loss: 0.3934 - val_accuracy: 0.8248\n",
            "Epoch 79/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.8167\n",
            "Epoch 00079: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0033808955922722816\n",
            "Elapsed time : 106.22s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.4007 - accuracy: 0.8167 - val_loss: 0.4591 - val_accuracy: 0.7846\n",
            "Epoch 80/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.8168\n",
            "Epoch 00080: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.003109423443675041\n",
            "Elapsed time : 106.10s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.4000 - accuracy: 0.8168 - val_loss: 0.3971 - val_accuracy: 0.8224\n",
            "Epoch 81/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.8170\n",
            "Epoch 00081: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0028434395790100098\n",
            "Elapsed time : 105.32s\n",
            "2437/2437 [==============================] - 105s 43ms/step - loss: 0.3993 - accuracy: 0.8170 - val_loss: 0.4191 - val_accuracy: 0.8082\n",
            "Epoch 82/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8170\n",
            "Epoch 00082: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0025839931331574917\n",
            "Elapsed time : 104.08s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.3980 - accuracy: 0.8170 - val_loss: 0.3736 - val_accuracy: 0.8396\n",
            "Epoch 83/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8176\n",
            "Epoch 00083: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.002332108560949564\n",
            "Elapsed time : 104.14s\n",
            "2437/2437 [==============================] - 104s 43ms/step - loss: 0.3978 - accuracy: 0.8176 - val_loss: 0.3958 - val_accuracy: 0.8240\n",
            "Epoch 84/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.3979 - accuracy: 0.8173\n",
            "Epoch 00084: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0020887793507426977\n",
            "Elapsed time : 106.38s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.3979 - accuracy: 0.8172 - val_loss: 0.5426 - val_accuracy: 0.7377\n",
            "Epoch 85/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3960 - accuracy: 0.8183\n",
            "Epoch 00085: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0018549663946032524\n",
            "Elapsed time : 106.66s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3960 - accuracy: 0.8183 - val_loss: 0.3771 - val_accuracy: 0.8377\n",
            "Epoch 86/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.3956 - accuracy: 0.8187\n",
            "Epoch 00086: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0016315920511260629\n",
            "Elapsed time : 106.34s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.3956 - accuracy: 0.8187 - val_loss: 0.3914 - val_accuracy: 0.8263\n",
            "Epoch 87/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.3955 - accuracy: 0.8187\n",
            "Epoch 00087: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0014195380499586463\n",
            "Elapsed time : 106.38s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.3954 - accuracy: 0.8187 - val_loss: 0.3899 - val_accuracy: 0.8288\n",
            "Epoch 88/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.8198\n",
            "Epoch 00088: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0012196411844342947\n",
            "Elapsed time : 106.86s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3943 - accuracy: 0.8198 - val_loss: 0.3772 - val_accuracy: 0.8388\n",
            "Epoch 89/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8197\n",
            "Epoch 00089: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0010326904011890292\n",
            "Elapsed time : 106.78s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3940 - accuracy: 0.8197 - val_loss: 0.4506 - val_accuracy: 0.7855\n",
            "Epoch 90/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.3940 - accuracy: 0.8199\n",
            "Epoch 00090: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.000859423540532589\n",
            "Elapsed time : 106.24s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.3940 - accuracy: 0.8199 - val_loss: 0.3776 - val_accuracy: 0.8428\n",
            "Epoch 91/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8207\n",
            "Epoch 00091: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0007005243096500635\n",
            "Elapsed time : 107.03s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3940 - accuracy: 0.8207 - val_loss: 0.3848 - val_accuracy: 0.8341\n",
            "Epoch 92/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8200\n",
            "Epoch 00092: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0005566199542954564\n",
            "Elapsed time : 106.73s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3945 - accuracy: 0.8200 - val_loss: 0.3941 - val_accuracy: 0.8311\n",
            "Epoch 93/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8208\n",
            "Epoch 00093: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.00042827826109714806\n",
            "Elapsed time : 106.77s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3933 - accuracy: 0.8208 - val_loss: 0.3953 - val_accuracy: 0.8256\n",
            "Epoch 94/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8212\n",
            "Epoch 00094: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0003160058113280684\n",
            "Elapsed time : 106.63s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.3942 - accuracy: 0.8212 - val_loss: 0.3936 - val_accuracy: 0.8348\n",
            "Epoch 95/100\n",
            "2436/2437 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.8211\n",
            "Epoch 00095: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.00022024568170309067\n",
            "Elapsed time : 106.48s\n",
            "2437/2437 [==============================] - 106s 44ms/step - loss: 0.3960 - accuracy: 0.8211 - val_loss: 0.3907 - val_accuracy: 0.8332\n",
            "Epoch 96/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.8203\n",
            "Epoch 00096: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0001413757709087804\n",
            "Elapsed time : 107.93s\n",
            "2437/2437 [==============================] - 108s 44ms/step - loss: 0.4000 - accuracy: 0.8203 - val_loss: 0.4047 - val_accuracy: 0.8280\n",
            "Epoch 97/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.8180\n",
            "Epoch 00097: val_loss did not improve from 0.36152\n",
            "Current learning rate 7.970737351570278e-05\n",
            "Elapsed time : 107.51s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.4098 - accuracy: 0.8180 - val_loss: 0.4217 - val_accuracy: 0.8211\n",
            "Epoch 98/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8101\n",
            "Epoch 00098: val_loss did not improve from 0.36152\n",
            "Current learning rate 3.548384484020062e-05\n",
            "Elapsed time : 107.10s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.4324 - accuracy: 0.8101 - val_loss: 0.4457 - val_accuracy: 0.8146\n",
            "Epoch 99/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.7938\n",
            "Epoch 00099: val_loss did not improve from 0.36152\n",
            "Current learning rate 8.879722372512333e-06\n",
            "Elapsed time : 107.23s\n",
            "2437/2437 [==============================] - 107s 44ms/step - loss: 0.4765 - accuracy: 0.7938 - val_loss: 0.5052 - val_accuracy: 0.7896\n",
            "Epoch 100/100\n",
            "2437/2437 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.7490\n",
            "Epoch 00100: val_loss did not improve from 0.36152\n",
            "Current learning rate 0.0\n",
            "Elapsed time : 108.02s\n",
            "Restarts\n",
            "2437/2437 [==============================] - 109s 45ms/step - loss: 0.5617 - accuracy: 0.7490 - val_loss: 0.6257 - val_accuracy: 0.6618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ub6x30OnGRC",
        "outputId": "7bf6b7d0-3e3a-4348-a367-57934f271b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}